{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "465107c9-89fd-4dbc-abc2-bd1141565f8b",
   "metadata": {},
   "source": [
    "# Co-learning with Memory Fusion Network (MFN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f13c08-9188-4445-a746-a52e781c0d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f8f5af0-6a91-4cb5-a9fc-d4a249794be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "from training_loops import train_ef_IM_bi, train_mfn\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import h5py\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90f8face-6d10-4233-aa4f-7cb01ca3185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d106d3-1515-4981-bc3c-383950fef90e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c325caf7-0292-4a21-a3ee-3983e4205158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_saved_data():\n",
    "\th5f = h5py.File('../data/MOSI/X_train.h5','r')\n",
    "\tX_train = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('../data/MOSI/y_train.h5','r')\n",
    "\ty_train = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('../data/MOSI/X_valid.h5','r')\n",
    "\tX_valid = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('../data/MOSI/y_valid.h5','r')\n",
    "\ty_valid = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('../data/MOSI/X_test.h5','r')\n",
    "\tX_test = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('../data/MOSI/y_test.h5','r')\n",
    "\ty_test = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\treturn X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47747258-c465-4af4-8a5f-5f25e2a9e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is read in in as Data Size x Sequence Len x Num Features. Please Note Num Features is organized as 300 text, 20 visual, 5 audio TODO CONFIRM THIS I also believe the start of time sequence is padded with zeros\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_saved_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83c03228-1f18-4d61-bc6d-3da29e387a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also need a version of the training data that only has the text modalitiy\n",
    "X_train_text_modality, X_valid_text_modality, X_test_text_modality = copy.deepcopy(X_train), copy.deepcopy(X_valid), copy.deepcopy(X_test)\n",
    "y_train_text_modality, y_valid_text_modality, y_test_text_modality = copy.deepcopy(y_train), copy.deepcopy(y_valid), copy.deepcopy(y_test)\n",
    "\n",
    "#We are only taking the first 300 features (corresponding to text modality)\n",
    "X_train_text_modality[:,:,300:] = 0.0\n",
    "X_valid_text_modality[:,:,300:] = 0.0\n",
    "X_test_text_modality[:,:,300:] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8c800-0743-4489-af7b-e88d252e4351",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36d5ade1-6abb-49b6-b8fa-553956dd6313",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict()\n",
    "config[\"input_dims\"] = [300,5,20]\n",
    "hl = 128\n",
    "ha = 32\n",
    "hv = 32\n",
    "config[\"h_dims\"] = [hl,ha,hv]\n",
    "config[\"memsize\"] = 128\n",
    "config[\"windowsize\"] = 2\n",
    "config[\"batchsize\"] = 128\n",
    "config[\"num_epochs\"] = 50\n",
    "config[\"lr\"] = .01\n",
    "config[\"momentum\"] = .9\n",
    "NN1Config = dict()\n",
    "NN1Config[\"shapes\"] = 128\n",
    "NN1Config[\"drop\"] = 0.0\n",
    "NN2Config = dict()\n",
    "NN2Config[\"shapes\"] = 64\n",
    "NN2Config[\"drop\"] = .2\n",
    "gamma1Config = dict()\n",
    "gamma1Config[\"shapes\"] = 256\n",
    "gamma1Config[\"drop\"] = 0.0\n",
    "gamma2Config = dict()\n",
    "gamma2Config[\"shapes\"] = 64\n",
    "gamma2Config[\"drop\"] = .2\n",
    "outConfig = dict()\n",
    "outConfig[\"shapes\"] =64\n",
    "outConfig[\"drop\"] = .5\n",
    "configs = [config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67c9494-cb36-4c05-b968-66e9a4bd0dcc",
   "metadata": {},
   "source": [
    "## Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0ad8fcb-293b-43d6-9c08-651f1b0583e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/Users/nicholasmagal/opt/anaconda3/envs/new_mmml/lib/python3.8/site-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/Users/nicholasmagal/opt/anaconda3/envs/new_mmml/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "  0%|          | 0/7 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3979162573814392 1.4017857313156128 saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/mfn_50494.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6d/_fq6qgb54_gbt5w6f1246nd80000gn/T/ipykernel_61438/4198741772.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0ml_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod_drop_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         results = train_mfn(X_train, y_train, X_valid_text_modality, y_valid, X_test_text_modality, \n\u001b[0m\u001b[1;32m     14\u001b[0m                   y_test_text_modality, configs, a_d,v_d,l_d)\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/Modality_Drop_Co-learning/code/training_loops.py\u001b[0m in \u001b[0;36mtrain_mfn\u001b[0;34m(X_train, y_train, X_valid, y_valid, X_test, y_test, configs, audio_dropout, video_dropout, language_dropout)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0mbest_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saving model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output/mfn_%d.pt'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/new_mmml/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/new_mmml/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/new_mmml/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/mfn_50494.pt'"
     ]
    }
   ],
   "source": [
    "#Training Full Multimodal on different multimodal dropout settings\n",
    "total_seeds = 5\n",
    "for i in range(total_seeds):\n",
    "    set_seed(i)\n",
    "    modality_drop = [[0,0,0],[.15,.15,0],[.4,.4, 0],[.6,.6, 0], [.8,.8,0], [.9,.9,0], [.95,.95,0]]\n",
    "\n",
    "    res = []\n",
    "    for mod_drop_probs in tqdm(modality_drop):\n",
    "        a_d = mod_drop_probs[0]\n",
    "        v_d = mod_drop_probs[1]\n",
    "        l_d = mod_drop_probs[2]\n",
    "\n",
    "        results = train_mfn(X_train, y_train, X_valid_text_modality, y_valid, X_test_text_modality, \n",
    "                  y_test_text_modality, configs, a_d,v_d,l_d)\n",
    "\n",
    "        res.append(results)\n",
    "    \n",
    "    #Training Unimodal Version \n",
    "    results = train_mfn(X_train_text_modality, y_train_text_modality,\n",
    "          X_valid_text_modality, y_valid_text_modality, \n",
    "          X_test_text_modality, y_test_text_modality, \n",
    "          configs, 0, 0, 0)\n",
    "    \n",
    "    #setting N/A since it is unimodal \n",
    "    results[0] = 'N/A'\n",
    "    results[1] = 'N/A'\n",
    "    results[2] = 'N/A'\n",
    "    res.append(results)\n",
    "    \n",
    "    #writing results\n",
    "    cols = ['audio_dropout', 'language_dropout', 'video_dropout', 'acc', 'mae', 'f_score']\n",
    "    result_df = pd.DataFrame(res, columns = cols)\n",
    "    result_df.to_csv('../output/co_learning_MFN_MOSI/dropout_results_'+ str(i)+ '.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1117976a-d94c-40b0-af2b-57332b855cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
